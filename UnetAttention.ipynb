{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNvXTn58g0uWu2ovCw3oC/l"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"OzBWsxO5Md_k"},"outputs":[],"source":["import os\n","import numpy as np\n","import scipy.io as sio\n","from PIL import Image\n","import cv2\n","import scipy\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["# Load .mat file\n","mat_file = '/content/drive/MyDrive/data/Speckle_mat_Train/0-label-5.mat'  # Modify to your .mat file path\n","data = scipy.io.loadmat(mat_file)\n","\n","# Get the first valid variable from the .mat file\n","# Usually image data will be a 2D or 3D array, try to extract the first one in order\n","for key in data:\n","    if not key.startswith('__'):  # Exclude metadata (such as '__header__', '__version__', etc.)\n","        image_data = data[key]\n","        break\n","\n","# Print image height and width\n","height, width = image_data.shape[:2]\n","print(f'Image Height: {height}, Image Width: {width}')\n","\n","# Display image\n","plt.imshow(image_data, cmap='gray')  # Use grayscale, remove cmap if it's a color image\n","plt.axis('off')  # Turn off coordinate axis\n","plt.show()"],"metadata":{"id":"RNP5eB6xMhSc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_directories(dirs):\n","    \"\"\"Create necessary directories\"\"\"\n","    for dir_path in dirs:\n","        os.makedirs(dir_path, exist_ok=True)\n","        print(f\"Created directory: {dir_path}\")\n","\n","def convert_mat_to_png(mat_dir, save_dir):\n","    \"\"\"Convert .mat files to PNG format\"\"\"\n","    # Get all .mat files\n","    mat_files = [f for f in os.listdir(mat_dir) if f.endswith('.mat')]\n","    mat_files.sort(key=lambda x: int(x.split('-')[0]))  # Sort by numerical order\n","\n","    for mat_file in mat_files:\n","        # Read .mat file\n","        mat_path = os.path.join(mat_dir, mat_file)\n","        mat_data = sio.loadmat(mat_path)[\"data\"].astype(np.float32)\n","\n","        # Normalize to [0, 255]\n","        mat_data = (mat_data - mat_data.min()) / (mat_data.max() - mat_data.min()) * 255\n","        mat_data = mat_data.astype(np.uint8)\n","\n","        # Convert to PNG and save\n","        img = Image.fromarray(mat_data)\n","        save_path = os.path.join(save_dir, mat_file.replace('.mat', '.png'))\n","        img.save(save_path)\n","        print(f\"Converted: {mat_file} -> {os.path.basename(save_path)}\")\n","\n","def resize_and_save_labels(label_dir, save_dir, target_size=(256, 256)):\n","    \"\"\"Resize label images and save\"\"\"\n","    # Get all PNG files\n","    label_files = [f for f in os.listdir(label_dir) if f.endswith('.png')]\n","    label_files.sort(key=lambda x: int(x.split('-')[0]))  # Sort by numerical order\n","\n","    for label_file in label_files:\n","        # Read label image\n","        label_path = os.path.join(label_dir, label_file)\n","        label_img = Image.open(label_path).convert('L')\n","\n","        # Resize\n","        resized_img = label_img.resize(target_size, Image.LANCZOS)\n","\n","        # Save resized image\n","        save_path = os.path.join(save_dir, label_file)\n","        resized_img.save(save_path)\n","        print(f\"Resized and saved: {label_file}\")"],"metadata":{"id":"9PmvPzNPR0D3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set paths\n","mat_dir = '/content/drive/MyDrive/data/Speckle_mat_Train'\n","label_dir = '/content/drive/MyDrive/data/DataImages-Train'\n","train_png_dir = 'train_png'\n","label_png_dir = 'label_png'\n","\n","# Create necessary directories\n","create_directories([train_png_dir, label_png_dir])\n","\n","# Convert .mat files to PNG\n","print(\"\\nConverting .mat files to PNG...\")\n","convert_mat_to_png(mat_dir, train_png_dir)\n","\n","# Resize and save label images\n","print(\"\\nResizing and saving label images...\")\n","resize_and_save_labels(label_dir, label_png_dir)\n","\n","print(\"\\nData preprocessing completed!\")"],"metadata":{"id":"5nFupCHaR3IN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms"],"metadata":{"id":"Q5lCcbzqR9P1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class SpeckleDataset(Dataset):\n","    def __init__(self, train_dir, label_dir, transform=None):\n","        self.train_dir = train_dir\n","        self.label_dir = label_dir\n","        self.transform = transform\n","\n","        # Get all training image filenames\n","        self.image_files = [f for f in os.listdir(train_dir) if f.endswith('.png')]\n","        self.image_files.sort(key=lambda x: int(x.split('-')[0]))\n","\n","    def __len__(self):\n","        return len(self.image_files)\n","\n","    def __getitem__(self, idx):\n","        # Read training image\n","        img_name = self.image_files[idx]\n","        img_path = os.path.join(self.train_dir, img_name)\n","        label_path = os.path.join(self.label_dir, img_name)\n","\n","        # Read image and label\n","        image = Image.open(img_path).convert('L')\n","        label = Image.open(label_path).convert('L')\n","\n","        if self.transform:\n","            image = self.transform(image)\n","            label = self.transform(label)\n","\n","        return image, label"],"metadata":{"id":"_qOnzXqKSCKs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class UNetWithAttention(nn.Module):\n","    def __init__(self):\n","        super(UNetWithAttention, self).__init__()\n","\n","        # Encoder\n","        self.enc1 = self.conv_block(1, 64)\n","        self.enc2 = self.conv_block(64, 128)\n","        self.enc3 = self.conv_block(128, 256)\n","        self.enc4 = self.conv_block(256, 512)\n","\n","        # Middle layer\n","        self.center = self.conv_block(512, 1024)\n","\n","        # Decoder\n","        self.dec4 = self.up_conv(1024, 512)\n","        self.dec3 = self.up_conv(512, 256)\n","        self.dec2 = self.up_conv(256, 128)\n","        self.dec1 = self.up_conv(128, 64)\n","\n","        # Attention mechanism\n","        self.attention4 = self.attention_block(512)\n","        self.attention3 = self.attention_block(256)\n","        self.attention2 = self.attention_block(128)\n","        self.attention1 = self.attention_block(64)\n","\n","        # Output layer\n","        self.final = nn.Conv2d(64, 1, kernel_size=1)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def conv_block(self, in_ch, out_ch):\n","        return nn.Sequential(\n","            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n","            nn.BatchNorm2d(out_ch),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n","            nn.BatchNorm2d(out_ch),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def up_conv(self, in_ch, out_ch):\n","        return nn.Sequential(\n","            nn.ConvTranspose2d(in_ch, out_ch, 2, stride=2),\n","            self.conv_block(out_ch, out_ch)\n","        )\n","\n","    def attention_block(self, ch):\n","        return nn.Sequential(\n","            nn.Conv2d(ch, ch, 1),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        # Encoding path\n","        e1 = self.enc1(x)\n","        e2 = self.enc2(nn.MaxPool2d(2)(e1))\n","        e3 = self.enc3(nn.MaxPool2d(2)(e2))\n","        e4 = self.enc4(nn.MaxPool2d(2)(e3))\n","\n","        # Middle layer\n","        center = self.center(nn.MaxPool2d(2)(e4))\n","\n","        # Decoding path (with attention mechanism)\n","        d4 = self.dec4(center)\n","        d4 = d4 * self.attention4(e4)\n","\n","        d3 = self.dec3(d4)\n","        d3 = d3 * self.attention3(e3)\n","\n","        d2 = self.dec2(d3)\n","        d2 = d2 * self.attention2(e2)\n","\n","        d1 = self.dec1(d2)\n","        d1 = d1 * self.attention1(e1)\n","\n","        out = self.sigmoid(self.final(d1))\n","        return out"],"metadata":{"id":"Ha6kcc7ASHdj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def visualize_results(model, val_loader, device, epoch, save_dir='results'):\n","    model.eval()\n","    os.makedirs(save_dir, exist_ok=True)\n","\n","    with torch.no_grad():\n","        # Get a batch of data\n","        inputs, labels = next(iter(val_loader))\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        outputs = model(inputs)\n","\n","        # Select the first sample for visualization\n","        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n","\n","        # Display input image\n","        axes[0].imshow(inputs[0,0].cpu().numpy(), cmap='gray')\n","        axes[0].set_title('Input Image')\n","        axes[0].axis('off')\n","\n","        # Display ground truth\n","        axes[1].imshow(labels[0,0].cpu().numpy(), cmap='gray')\n","        axes[1].set_title('Ground Truth')\n","        axes[1].axis('off')\n","\n","        # Display prediction\n","        axes[2].imshow(outputs[0,0].cpu().numpy(), cmap='gray')\n","        axes[2].set_title('Prediction')\n","        axes[2].axis('off')\n","\n","        plt.suptitle(f'Epoch {epoch}')\n","        plt.tight_layout()\n","        plt.savefig(os.path.join(save_dir, f'result_epoch_{epoch}.png'))\n","        plt.close()"],"metadata":{"id":"-CZPwus7SIPB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n","    best_loss = float('inf')\n","\n","    for epoch in range(num_epochs):\n","        # Training phase\n","        model.train()\n","        train_loss = 0\n","        for inputs, labels in train_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss += loss.item()\n","\n","        # Validation phase\n","        model.eval()\n","        val_loss = 0\n","        with torch.no_grad():\n","            for inputs, labels in val_loader:\n","                inputs, labels = inputs.to(device), labels.to(device)\n","                outputs = model(inputs)\n","                loss = criterion(outputs, labels)\n","                val_loss += loss.item()\n","\n","        # Calculate average loss\n","        avg_train_loss = train_loss / len(train_loader)\n","        avg_val_loss = val_loss / len(val_loader)\n","\n","        # Print training information\n","        print(f'Epoch {epoch+1}/{num_epochs}:')\n","        print(f'Train Loss: {avg_train_loss:.4f}')\n","        print(f'Val Loss: {avg_val_loss:.4f}')\n","\n","        # Visualize current results\n","        visualize_results(model, val_loader, device, epoch+1)\n","\n","        # Save best model\n","        if avg_val_loss < best_loss:\n","            best_loss = avg_val_loss\n","            torch.save(model.state_dict(), 'best_model.pth')"],"metadata":{"id":"idtXj_EySQU4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set paths\n","train_dir = 'train_png'\n","label_dir = 'label_png'\n","\n","# Set device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Data transformation\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","])\n","\n","# Create dataset\n","dataset = SpeckleDataset(train_dir, label_dir, transform=transform)\n","\n","# Split training and validation sets\n","train_size = int(0.8 * len(dataset))\n","val_size = len(dataset) - train_size\n","train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n","\n","# Create data loaders\n","train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)"],"metadata":{"id":"akwv7CpFSRDu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize model\n","model = UNetWithAttention().to(device)\n","\n","# Define loss function and optimizer\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Train model\n","train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=100, device=device)"],"metadata":{"id":"1xQofy8LSXqq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict_single_image(model_path, mat_path, save_dir):\n","    \"\"\"\n","    Predict a single .mat image and save the result\n","\n","    Parameters:\n","    model_path: Path to the model file\n","    mat_path: Path to the .mat file to be predicted\n","    save_dir: Directory to save results\n","    \"\"\"\n","    # Create save directory\n","    os.makedirs(save_dir, exist_ok=True)\n","\n","    # Set device\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    # Load model\n","    model = UNetWithAttention().to(device)\n","    model.load_state_dict(torch.load(model_path))\n","    model.eval()\n","\n","    # Read .mat file\n","    mat_data = sio.loadmat(mat_path)[\"data\"].astype(np.float32)\n","\n","    # Preprocessing - same steps as during training\n","    # Normalize to [0, 255]\n","    mat_data = (mat_data - mat_data.min()) / (mat_data.max() - mat_data.min()) * 255\n","    mat_data = mat_data.astype(np.uint8)\n","\n","    # Convert to PIL Image\n","    img = Image.fromarray(mat_data)\n","\n","    # Apply same transformation\n","    transform = transforms.Compose([\n","        transforms.ToTensor(),\n","    ])\n","\n","    # Transform image\n","    img_tensor = transform(img).unsqueeze(0)  # Add batch dimension\n","    img_tensor = img_tensor.to(device)\n","\n","    # Make prediction\n","    with torch.no_grad():\n","        output = model(img_tensor)\n","        prediction = output.squeeze().cpu().numpy()\n","\n","    # Post-processing - convert prediction to image\n","    prediction = (prediction * 255).astype(np.uint8)\n","    prediction_img = Image.fromarray(prediction)\n","\n","    # Save prediction\n","    # Get original filename (without path) and replace .mat with .png\n","    save_filename = os.path.basename(mat_path).replace('.mat', '.png')\n","    save_path = os.path.join(save_dir, save_filename)\n","    prediction_img.save(save_path)\n","\n","    print(f\"Prediction saved as: {save_path}\")\n","\n","    return save_path"],"metadata":{"id":"cXmgljnrSeM0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set paths\n","model_path = 'best_model.pth'  # Path to trained model\n","mat_path = '/content/drive/MyDrive/data/Speckle_mat_Val/10-label-5.mat'"],"metadata":{"id":"2u_uJfFrSe08"},"execution_count":null,"outputs":[]}]}